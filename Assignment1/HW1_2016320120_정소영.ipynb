{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #1 \n",
    "\n",
    "#### Machine Learning in Korea University\n",
    "#### COSE362, Fall 2018 (Prof. Jaewoo Kang)\n",
    "#### Due : 11/6 (TUE) 11:59 PM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this assignment, you will learn model selection process among various hyperparameters.\n",
    "* Implementation detail: Anaconda 5.3 with python 3.7\n",
    "* Use given dataset. Please do not change training / validation / test split.\n",
    "* Use numpy, scikit-learn, and matplotlib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression with Feature Selection\n",
    "In this example we will conduct featrue selection process in linear regression model. <br>\n",
    "You will use data in 'LinReg' directory for this example. <br>\n",
    "Please perform the following steps. \n",
    "> 0. Preprocess: Change given dataset into input array for scikit-learn model.\n",
    "> 1. Feture selection : perform greedy feature selection.\n",
    "> 2. Plot: plot validation and train error against number of feature.\n",
    "> 3. Model selection and evaluation: Select best model and perform evaluation on test dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-0. Preprocess\n",
    "Load dataset and process it into appropriate array form.\n",
    "* Example <br>\n",
    "> For linear regression problem, the datasets are described onto 'dev_sample.npy', 'dev_label.npy', 'test_sample.npy', 'test_label.npy' in 'LinReg' folder. <br>\n",
    "> Load these datasets onto <b>X_dev, y_dev, X_test, y_test</b>. <br>\n",
    "> You may need to use numpy.load function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load linear regression datasets\n",
    "# Your code here\n",
    "X_dev = np.load(\"./LinReg/dev_sample.npy\")\n",
    "y_dev = np.load(\"./LinReg/dev_label.npy\")\n",
    "X_test = np.load(\"./LinReg/test_sample.npy\")\n",
    "y_test = np.load(\"./LinReg/test_label.npy\")\n",
    "# End your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Feature selection\n",
    "Build linear regression models with different number of features. (1 ~ 100)<br>\n",
    "Please use <b>cross validation</b>, <b>greedy approach</b> for feature selection until choose optimal number of features. <br> \n",
    "\n",
    "* For cross validaton, you need to split your development set into 5-fold. This is implemented into class <b>cv</b>.\n",
    "* Feature selection example : Input with 10 features\n",
    "> Call 10 features as #1, #2, #3, ..., #10 <br>\n",
    "> First build 10 models with only one feature. \n",
    "> Compare model with #1, model with #2, ... , model with #10 <br>\n",
    "> Choose feature of the best model. (for example, #1 is the best) <br>\n",
    "> Build model with 2 features. (#1, #2), (#1, #3), ..., (#1, #10). <br>\n",
    "> Then, add feature with the best performance. <br>\n",
    "> And so on...\n",
    "\n",
    "<b>For the next step, please save validation and train error of the best model for each number of selected features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "# of selected feature(s) : 1\n",
      "Selected feature of this iteration : 1\n",
      "==================================================\n",
      "# of selected feature(s) : 2\n",
      "Selected feature of this iteration : 3\n",
      "==================================================\n",
      "# of selected feature(s) : 3\n",
      "Selected feature of this iteration : 45\n",
      "==================================================\n",
      "# of selected feature(s) : 4\n",
      "Selected feature of this iteration : 109\n",
      "==================================================\n",
      "# of selected feature(s) : 5\n",
      "Selected feature of this iteration : 53\n",
      "==================================================\n",
      "# of selected feature(s) : 6\n",
      "Selected feature of this iteration : 44\n",
      "==================================================\n",
      "# of selected feature(s) : 7\n",
      "Selected feature of this iteration : 43\n",
      "==================================================\n",
      "# of selected feature(s) : 8\n",
      "Selected feature of this iteration : 116\n",
      "==================================================\n",
      "# of selected feature(s) : 9\n",
      "Selected feature of this iteration : 95\n",
      "==================================================\n",
      "# of selected feature(s) : 10\n",
      "Selected feature of this iteration : 21\n",
      "==================================================\n",
      "# of selected feature(s) : 11\n",
      "Selected feature of this iteration : 77\n",
      "==================================================\n",
      "# of selected feature(s) : 12\n",
      "Selected feature of this iteration : 80\n",
      "==================================================\n",
      "# of selected feature(s) : 13\n",
      "Selected feature of this iteration : 97\n",
      "==================================================\n",
      "# of selected feature(s) : 14\n",
      "Selected feature of this iteration : 26\n",
      "==================================================\n",
      "# of selected feature(s) : 15\n",
      "Selected feature of this iteration : 24\n",
      "==================================================\n",
      "# of selected feature(s) : 16\n",
      "Selected feature of this iteration : 36\n",
      "==================================================\n",
      "# of selected feature(s) : 17\n",
      "Selected feature of this iteration : 40\n",
      "==================================================\n",
      "# of selected feature(s) : 18\n",
      "Selected feature of this iteration : 117\n",
      "==================================================\n",
      "# of selected feature(s) : 19\n",
      "Selected feature of this iteration : 92\n",
      "==================================================\n",
      "# of selected feature(s) : 20\n",
      "Selected feature of this iteration : 84\n",
      "==================================================\n",
      "# of selected feature(s) : 21\n",
      "Selected feature of this iteration : 110\n",
      "==================================================\n",
      "# of selected feature(s) : 22\n",
      "Selected feature of this iteration : 98\n",
      "==================================================\n",
      "# of selected feature(s) : 23\n",
      "Selected feature of this iteration : 15\n",
      "==================================================\n",
      "# of selected feature(s) : 24\n",
      "Selected feature of this iteration : 6\n",
      "==================================================\n",
      "# of selected feature(s) : 25\n",
      "Selected feature of this iteration : 118\n",
      "==================================================\n",
      "# of selected feature(s) : 26\n",
      "Selected feature of this iteration : 85\n",
      "==================================================\n",
      "# of selected feature(s) : 27\n",
      "Selected feature of this iteration : 113\n",
      "==================================================\n",
      "# of selected feature(s) : 28\n",
      "Selected feature of this iteration : 0\n",
      "==================================================\n",
      "# of selected feature(s) : 29\n",
      "Selected feature of this iteration : 69\n",
      "==================================================\n",
      "# of selected feature(s) : 30\n",
      "Selected feature of this iteration : 99\n",
      "==================================================\n",
      "# of selected feature(s) : 31\n",
      "Selected feature of this iteration : 104\n",
      "==================================================\n",
      "# of selected feature(s) : 32\n",
      "Selected feature of this iteration : 31\n",
      "==================================================\n",
      "# of selected feature(s) : 33\n",
      "Selected feature of this iteration : 62\n",
      "==================================================\n",
      "# of selected feature(s) : 34\n",
      "Selected feature of this iteration : 121\n",
      "==================================================\n",
      "# of selected feature(s) : 35\n",
      "Selected feature of this iteration : 35\n",
      "==================================================\n",
      "# of selected feature(s) : 36\n",
      "Selected feature of this iteration : 120\n",
      "==================================================\n",
      "# of selected feature(s) : 37\n",
      "Selected feature of this iteration : 17\n",
      "==================================================\n",
      "# of selected feature(s) : 38\n",
      "Selected feature of this iteration : 42\n",
      "==================================================\n",
      "# of selected feature(s) : 39\n",
      "Selected feature of this iteration : 25\n",
      "==================================================\n",
      "# of selected feature(s) : 40\n",
      "Selected feature of this iteration : 108\n",
      "==================================================\n",
      "# of selected feature(s) : 41\n",
      "Selected feature of this iteration : 51\n",
      "==================================================\n",
      "# of selected feature(s) : 42\n",
      "Selected feature of this iteration : 14\n",
      "==================================================\n",
      "# of selected feature(s) : 43\n",
      "Selected feature of this iteration : 2\n",
      "==================================================\n",
      "# of selected feature(s) : 44\n",
      "Selected feature of this iteration : 22\n",
      "==================================================\n",
      "# of selected feature(s) : 45\n",
      "Selected feature of this iteration : 57\n",
      "==================================================\n",
      "# of selected feature(s) : 46\n",
      "Selected feature of this iteration : 81\n",
      "==================================================\n",
      "# of selected feature(s) : 47\n",
      "Selected feature of this iteration : 65\n",
      "==================================================\n",
      "# of selected feature(s) : 48\n",
      "Selected feature of this iteration : 33\n",
      "==================================================\n",
      "# of selected feature(s) : 49\n",
      "Selected feature of this iteration : 37\n",
      "==================================================\n",
      "# of selected feature(s) : 50\n",
      "Selected feature of this iteration : 30\n",
      "==================================================\n",
      "# of selected feature(s) : 51\n",
      "Selected feature of this iteration : 11\n",
      "==================================================\n",
      "# of selected feature(s) : 52\n",
      "Selected feature of this iteration : 71\n",
      "==================================================\n",
      "# of selected feature(s) : 53\n",
      "Selected feature of this iteration : 18\n",
      "==================================================\n",
      "# of selected feature(s) : 54\n",
      "Selected feature of this iteration : 50\n",
      "==================================================\n",
      "# of selected feature(s) : 55\n",
      "Selected feature of this iteration : 102\n",
      "==================================================\n",
      "# of selected feature(s) : 56\n",
      "Selected feature of this iteration : 66\n",
      "==================================================\n",
      "# of selected feature(s) : 57\n",
      "Selected feature of this iteration : 75\n",
      "==================================================\n",
      "# of selected feature(s) : 58\n",
      "Selected feature of this iteration : 46\n",
      "==================================================\n",
      "# of selected feature(s) : 59\n",
      "Selected feature of this iteration : 49\n",
      "==================================================\n",
      "# of selected feature(s) : 60\n",
      "Selected feature of this iteration : 10\n",
      "==================================================\n",
      "# of selected feature(s) : 61\n",
      "Selected feature of this iteration : 34\n",
      "==================================================\n",
      "# of selected feature(s) : 62\n",
      "Selected feature of this iteration : 100\n",
      "==================================================\n",
      "# of selected feature(s) : 63\n",
      "Selected feature of this iteration : 114\n",
      "==================================================\n",
      "# of selected feature(s) : 64\n",
      "Selected feature of this iteration : 54\n",
      "==================================================\n",
      "# of selected feature(s) : 65\n",
      "Selected feature of this iteration : 39\n",
      "==================================================\n",
      "# of selected feature(s) : 66\n",
      "Selected feature of this iteration : 7\n",
      "==================================================\n",
      "# of selected feature(s) : 67\n",
      "Selected feature of this iteration : 4\n",
      "==================================================\n",
      "# of selected feature(s) : 68\n",
      "Selected feature of this iteration : 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "# of selected feature(s) : 69\n",
      "Selected feature of this iteration : 124\n",
      "==================================================\n",
      "# of selected feature(s) : 70\n",
      "Selected feature of this iteration : 5\n",
      "==================================================\n",
      "# of selected feature(s) : 71\n",
      "Selected feature of this iteration : 86\n",
      "==================================================\n",
      "# of selected feature(s) : 72\n",
      "Selected feature of this iteration : 55\n",
      "==================================================\n",
      "# of selected feature(s) : 73\n",
      "Selected feature of this iteration : 16\n",
      "==================================================\n",
      "# of selected feature(s) : 74\n",
      "Selected feature of this iteration : 27\n",
      "==================================================\n",
      "# of selected feature(s) : 75\n",
      "Selected feature of this iteration : 61\n",
      "==================================================\n",
      "# of selected feature(s) : 76\n",
      "Selected feature of this iteration : 32\n",
      "==================================================\n",
      "# of selected feature(s) : 77\n",
      "Selected feature of this iteration : 23\n",
      "==================================================\n",
      "# of selected feature(s) : 78\n",
      "Selected feature of this iteration : 41\n",
      "==================================================\n",
      "# of selected feature(s) : 79\n",
      "Selected feature of this iteration : 87\n",
      "==================================================\n",
      "# of selected feature(s) : 80\n",
      "Selected feature of this iteration : 9\n",
      "==================================================\n",
      "# of selected feature(s) : 81\n",
      "Selected feature of this iteration : 59\n",
      "==================================================\n",
      "# of selected feature(s) : 82\n",
      "Selected feature of this iteration : 60\n",
      "==================================================\n",
      "# of selected feature(s) : 83\n",
      "Selected feature of this iteration : 73\n",
      "==================================================\n",
      "# of selected feature(s) : 84\n",
      "Selected feature of this iteration : 88\n",
      "==================================================\n",
      "# of selected feature(s) : 85\n",
      "Selected feature of this iteration : 72\n",
      "==================================================\n",
      "# of selected feature(s) : 86\n",
      "Selected feature of this iteration : 48\n",
      "==================================================\n",
      "# of selected feature(s) : 87\n",
      "Selected feature of this iteration : 67\n",
      "==================================================\n",
      "# of selected feature(s) : 88\n",
      "Selected feature of this iteration : 119\n",
      "==================================================\n",
      "# of selected feature(s) : 89\n",
      "Selected feature of this iteration : 103\n",
      "==================================================\n",
      "# of selected feature(s) : 90\n",
      "Selected feature of this iteration : 79\n",
      "==================================================\n",
      "# of selected feature(s) : 91\n",
      "Selected feature of this iteration : 64\n",
      "==================================================\n",
      "# of selected feature(s) : 92\n",
      "Selected feature of this iteration : 74\n",
      "==================================================\n",
      "# of selected feature(s) : 93\n",
      "Selected feature of this iteration : 13\n",
      "==================================================\n",
      "# of selected feature(s) : 94\n",
      "Selected feature of this iteration : 20\n",
      "==================================================\n",
      "# of selected feature(s) : 95\n",
      "Selected feature of this iteration : 105\n",
      "==================================================\n",
      "# of selected feature(s) : 96\n",
      "Selected feature of this iteration : 93\n",
      "==================================================\n",
      "# of selected feature(s) : 97\n",
      "Selected feature of this iteration : 91\n",
      "==================================================\n",
      "# of selected feature(s) : 98\n",
      "Selected feature of this iteration : 123\n",
      "==================================================\n",
      "# of selected feature(s) : 99\n",
      "Selected feature of this iteration : 47\n",
      "==================================================\n",
      "# of selected feature(s) : 100\n",
      "Selected feature of this iteration : 90\n"
     ]
    }
   ],
   "source": [
    "# Define linear regression function\n",
    "# You may use sklearn.linear_model.LinearRegression\n",
    "\n",
    "# Your code here\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#create linear regression model\n",
    "regr = linear_model.LinearRegression()\n",
    "# End your code\n",
    "\n",
    "# Basic settings. DO NOT MODIFY\n",
    "selected_feature = []\n",
    "sel_num = 100\n",
    "valid_split = 1/5\n",
    "cv = ShuffleSplit(n_splits=5, test_size=valid_split, random_state=0)\n",
    "\n",
    "selected_train_error = []\n",
    "selected_valid_error = []\n",
    "\n",
    "# For greedy selection\n",
    "min_valid_dict = {}\n",
    "for sel in range(sel_num) :\n",
    "    min_train_error = +1000\n",
    "    min_valid_error = +1000\n",
    "    min_feature = 0\n",
    "    \n",
    "    # For each feature\n",
    "    for i in range(X_dev.shape[1]) :\n",
    "        train_error_ith = []\n",
    "        valid_error_ith = []\n",
    "        \n",
    "        # Select feature greedy\n",
    "        # Hint : There should be no duplicated feature in selected_feature\n",
    "        # Your code here\n",
    "        \n",
    "        #print(selected_feature + [i])\n",
    "        temp = selected_feature + [i]\n",
    "        X_dev_fs = X_dev[:, temp]\n",
    "        # End your code\n",
    "        \n",
    "        \n",
    "        # For cross validation\n",
    "        for train_index, test_index in cv.split(X_dev) :\n",
    "            X_train, X_valid = X_dev_fs[train_index], X_dev_fs[test_index]\n",
    "            y_train, y_valid = y_dev[train_index], y_dev[test_index]\n",
    "        \n",
    "            # Derive training error, validation error\n",
    "            # You may use sklearn.metrics.mean_squared_error, model.fit(), model.predict()\n",
    "            # Your code here\n",
    "            \n",
    "            #Train the model using the training sets\n",
    "            regr.fit(X_train, y_train)\n",
    "            \n",
    "            #print(\"%dth\" % i)\n",
    "            #The coefficients\n",
    "            #print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "            #The mean squared error\n",
    "            train_error_ith.append(mean_squared_error(regr.predict(X_train), y_train))\n",
    "            valid_error_ith.append(mean_squared_error(regr.predict(X_valid), y_valid))\n",
    "\n",
    "            #Explained variance score: 1 is perfect prediction\n",
    "            #print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "            # End your code\n",
    "        \n",
    "        temp = np.mean(valid_error_ith)\n",
    "        \n",
    "        if temp <= min_valid_error:\n",
    "            if i in selected_feature:\n",
    "                continue\n",
    "            \n",
    "            min_valid_error = temp\n",
    "            min_train_error = np.mean(train_error_ith)\n",
    "            min_feature = i\n",
    "            min_valid_dict.update({i:min_valid_error})\n",
    "            \n",
    "            #print(\"%dth\"%i)\n",
    "            #print(min_train_error)\n",
    "                \n",
    "        # Select best performance feature set on each features\n",
    "        # You should choose the feature which has minimum mean cross validation error\n",
    "        # Your code here\n",
    "\n",
    "        # End your code\n",
    "\n",
    "    print('='*50)\n",
    "    print(\"# of selected feature(s) : {}\".format(sel+1))\n",
    "    print(\"Selected feature of this iteration : {}\".format(min_feature))\n",
    "    selected_feature.append(min_feature)\n",
    "    selected_train_error.append(min_train_error)\n",
    "    selected_valid_error.append(min_valid_error)\n",
    " \n",
    "\n",
    "#count = {}\n",
    "#for num in selected_feature:\n",
    "#    try: count[num] += 1\n",
    "#    except: count[num] = 1\n",
    "#print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Plot error\n",
    "Plot train and validation error against number of features.<br>\n",
    "After plotting, <b>analyze the result graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train error plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(np.arange(1,sel_num+1), selected_train_error)\n",
    "plt.title('Training error')\n",
    "plt.legend(['error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation error plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(np.arange(1,sel_num+1), selected_valid_error)\n",
    "plt.title('Validation error')\n",
    "plt.legend(['error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze\n",
    "Write explanation of graph below. <br>\n",
    "Analyze the folloing points.\n",
    "* Trend of each error against number of features\n",
    "* Meaning of gap between vlidation error and train error\n",
    "* Meaning of each region in graph\n",
    "* Others..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write description here\n",
    "1. Training error는 feature 개수가 늘어날수록, 즉 model complexity가 커질수록 줄어듭니다. Validation error는 feature 개수가 약 30개로 늘어날 때까지는 줄어드는 양상을 보이지만, 그 이상으로 feature 개수가 늘어나면 다시 증가합니다. \n",
    "\n",
    "2. 이러한 양상을 보이는 이유는, model complexity가 커질수록 주어진 dataset에 overfitting되기 때문입니다. feature개수가 늘어날수록, training sample의 noise까지 학습할 수 있기에 overfitting이 일어나, 일반화에 실패하고, 새로운 sample이 주어졌을 때 성능이 떨어집니다. 이 때문에 training error와 validation error사이의 gap이 발생합니다. \n",
    "\n",
    "3. feature개수가 optimal point의 feature 개수보다 적은 지점에서는 training error와 validation error가 모두 낮고, 이는 high bias되었다고 판단할 수 있습니다. feature개수가 optimal point의 feature개수보다 많은 지점에서는 training error는 작지만, validation error는 크므로, 이는 high variance되었다고 판단할 수 있습니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Model selection and evaluation\n",
    "Select the best model and perform a test on test dataset.<br>\n",
    "Print the <b>performance on test set</b> with <b>features of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "# of selected features : 30\n",
      "Selected features : \n",
      "[1, 3, 45, 109, 53, 44, 43, 116, 95, 21, 77, 80, 97, 26, 24, 36, 40, 117, 92, 84, 110, 98, 15, 6, 118, 85, 113, 0, 69, 99]\n",
      "Training error : 6.085476385088486\n",
      "Validation error : 4.522828368608628\n",
      "Test error : 7.679010560715177\n"
     ]
    }
   ],
   "source": [
    "# Select optimal feature set corresponding the minimum cross validation error\n",
    "# Your code here\n",
    "min_verror_index = -1\n",
    "\n",
    "for (index, error) in enumerate(selected_valid_error):\n",
    "    if error == np.min(selected_valid_error):\n",
    "        min_verror_index = index\n",
    "\n",
    "selected_feature = selected_feature[:min_verror_index+1]\n",
    "X_dev_fs = X_dev[:,selected_feature]\n",
    "\n",
    "# End your code\n",
    "\n",
    "# Basic settings. DO NOT MODIFY\n",
    "min_train_error = 1000\n",
    "min_valid_error = 1000\n",
    "optimal_param = np.array([])\n",
    "\n",
    "optimal_param = np.zeros(126)\n",
    "\n",
    "for train_index, test_index in cv.split(X_dev) :\n",
    "    X_train, X_valid = X_dev_fs[train_index], X_dev_fs[test_index]\n",
    "    y_train, y_valid = y_dev[train_index], y_dev[test_index]\n",
    "    \n",
    "    # Derive training error, validation error for each fold\n",
    "    # For each fold, you need to compare error with previous minimum error.\n",
    "    # Your code here\n",
    "    train_error = []\n",
    "    valid_error = []\n",
    "    temp_param = np.array([])\n",
    "    temp_param = np.zeros(126)\n",
    "   # print(\"%dth\")\n",
    "    #Train the model using the training sets\n",
    "    regr.fit(X_train, y_train)\n",
    "    \n",
    "    #The mean squared error\n",
    "    train_error.append(mean_squared_error(regr.predict(X_train), y_train))\n",
    "    valid_error.append(mean_squared_error(regr.predict(X_valid), y_valid))\n",
    "   # print(mean_squared_error(regr.predict(X_valid), y_valid))\n",
    "    \n",
    "    #The coefficients\n",
    " #   print('Coefficients: \\n', regr.coef_)\n",
    "    \n",
    "    for i in range(len(selected_feature)):\n",
    "       # print(selected_feature[i])\n",
    "        temp_param[selected_feature[i]] = regr.coef_[i]\n",
    "        #print(temp_param)\n",
    "            \n",
    "    if(np.mean(valid_error)<min_valid_error):\n",
    "        min_valid_error = np.mean(valid_error)\n",
    "        optimal_param = temp_param\n",
    "        min_train_error = np.mean(train_error)\n",
    "        \n",
    "#print(\"op\")\n",
    "#print(optimal_param)\n",
    "    # End your code\n",
    "\n",
    "# Find the best model on each fold\n",
    "# Derive test error with best performance model\n",
    "# Your code here\n",
    "#regr.intercept_ = optimal_param[0]\n",
    "regr.coef_ = optimal_param[:]\n",
    "test_error = mean_squared_error(regr.predict(X_test), y_test)\n",
    "# End your code\n",
    "\n",
    "# Drop features of final model\n",
    "print(\"Results\")\n",
    "print(\"# of selected features : {}\".format(len(selected_feature)))\n",
    "print(\"Selected features : \")\n",
    "print(selected_feature)\n",
    "\n",
    "# Drop test error and accuracy\n",
    "print(\"Training error : {}\".format(min_train_error))\n",
    "print(\"Validation error : {}\".format(min_valid_error))\n",
    "print(\"Test error : {}\".format(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression with Regularizer\n",
    "\n",
    "In this example you will explore the effect of regularization parameter.<br>\n",
    "You will use <b>'Heart Disease Dataset'</b> in <b>'LogReg'</b> for this example. <br>\n",
    "\n",
    "The goal is to predict the presence of heart disease given attributes of a patient.<br>\n",
    "The presence is integer valued from 0 (no presence) to 4, but you have to only distingush presensence (values 1,2,3,4) from absence (value 0). <br>\n",
    "Each attribute is described below. <br>\n",
    "\n",
    "> 1. age : age in years <br>\n",
    "> 2. sex : sex (1 = male; 0 = female) <br>\n",
    "> 3. cp : chest pain type <br>\n",
    "-- Value 1: typical angina <br>\n",
    "-- Value 2: atypical angina <br>\n",
    "-- Value 3: non-anginal pain <br>\n",
    "-- Value 4: asymptomatic  <br>\n",
    "> 4. trestbps : resting blood pressure (in mm Hg on admission to the hospital)  <br>\n",
    "> 5. chol : serum cholestoral in mg/dl  <br>\n",
    "> 6. fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) <br>\n",
    "> 7. restecg  : resting electrocardiographic results <br>\n",
    "-- Value 0: normal <br>\n",
    "-- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) <br>\n",
    "-- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria <br>\n",
    "> 8. thalach : maximum heart rate achieved <br>\n",
    "> 9. exang : exercise induced angina (1 = yes; 0 = no) <br>\n",
    "> 10. oldpeak : ST depression induced by exercise relative to rest <br>\n",
    "> 11. slope : the slope of the peak exercise ST segment <br>\n",
    "-- Value 1: upsloping <br>\n",
    "-- Value 2: flat <br>\n",
    "-- Value 3: downsloping  <br>\n",
    "> 12. ca : number of major vessels (0-3) colored by flourosopy  <br>\n",
    "> 13. thal : 3 = normal; 6 = fixed defect; 7 = reversable defect  <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-0. Preprocess\n",
    "\n",
    "Firstly, read training, validation and test datasets respectively. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(data_type):\n",
    "    f = open('./LogReg/' + data_type + '.data', 'r')\n",
    "\n",
    "    X, Y = [],[]\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        spl = line.split(',')\n",
    "        x = spl[:-1]\n",
    "        y = int(spl[-1])\n",
    "        \n",
    "        X.append(list(map(float, x)))\n",
    "        \n",
    "        # Define the variable 'binary_label'.\n",
    "        # Note that labels must be 1 or 0.\n",
    "        # Your code here\n",
    "        if y == 0:\n",
    "            binary_label = 0\n",
    "        else:\n",
    "            binary_label = 1\n",
    "        Y.append(binary_label)  # blank\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "X_tr, Y_tr = read_data('train')\n",
    "X_va, Y_va = read_data('valid')\n",
    "X_te, Y_te = read_data('test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization and Converting to one-hot vector\n",
    "\n",
    "Data preprocessing takes several steps after loading data. <br>\n",
    "1. <b>Normailze</b> numerical values. Normalization is defined as <b><i>normalized_value</i> = (value - mean) / std</b>. <br>\n",
    "   You should calculate mean and standard deviation (std) on <b> train data </b> and normalize train, valid and test data.\n",
    "2. For categorical attributes, <b>build dictionaries</b> of each attribute and convert the categorical values to <b>one-hot vectors</b>. <br>\n",
    "3. Concatenate all the obtained values. <br>\n",
    "\n",
    "If you have done correctly, you will get results that are same format as below: \n",
    "* <b>before</b> : [63.0, 1.0, 1.0, 145.0, 233.0, 1.0, 2.0, 150.0, 0.0, 2.3, 3.0, 0.0, 6.0]\n",
    "* <b>after</b> : [0.11099784710934087, 0, 1, 1, 0, 0, 0, 0.035386000081823056, -0.005256085700922788, 0, 1, 0, 0, 1, 0.0026598418293161848, 1, 0, 0.6659671864819814, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0] <br>\n",
    "(The values in the above example can be different from actual values.)<br>\n",
    "\n",
    "<b>Do not use any library such as sklearn.preprocessing. You can use only Numpy. </b><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "X_tr = np.asarray(X_tr)\n",
    "Y_tr = np.asarray(Y_tr)\n",
    "X_va = np.asarray(X_va)\n",
    "Y_va = np.asarray(Y_va)\n",
    "X_te = np.asarray(X_te)\n",
    "Y_te = np.asarray(Y_te)\n",
    "\n",
    "#numerical values\n",
    "numerical_feature = [0,3,4,7,9]\n",
    "for feature_num in numerical_feature:\n",
    "    feature_mean = np.mean(X_tr[:,feature_num])\n",
    "    feature_std = np.std(X_tr[:,feature_num])\n",
    "    #normalization\n",
    "    X_tr[:,feature_num] = (X_tr[:,feature_num] - feature_mean) / feature_std\n",
    "    X_va[:,feature_num] = (X_va[:,feature_num] - feature_mean) / feature_std\n",
    "    X_te[:,feature_num] = (X_te[:,feature_num] - feature_mean) / feature_std\n",
    "#categorical values\n",
    "categorical_feature = [1,2,5,6,8,10,11,12] #2, 3, 6, 7, 9, 11, 12, 13\n",
    "\n",
    "feature_dict = {}\n",
    "\n",
    "for feature_num in (categorical_feature):\n",
    "    X_tr_value = X_tr[:,feature_num]\n",
    "    X_va_value = X_va[:,feature_num]\n",
    "    X_te_value = X_te[:,feature_num]\n",
    "    feature_set = set(X_tr_value)\n",
    "    \n",
    "   # print(X_tr_value)\n",
    "    \n",
    "    for (i, value) in enumerate(feature_set):\n",
    "        feature_dict[value] = i\n",
    "        \n",
    "    for (i, value) in enumerate(X_tr_value): \n",
    "        X_tr_value[i] = feature_dict[value]\n",
    "    for (i, value) in enumerate(X_va_value):\n",
    "        X_va_value[i] = feature_dict[value]\n",
    "    for (i, value) in enumerate(X_te_value):\n",
    "        X_te_value[i] = feature_dict[value]\n",
    "    \n",
    "    #print(X_te_value)\n",
    "    #print(X_tr_value)\n",
    "    #print(X_va_value)\n",
    "    \n",
    "    nb_class = len(feature_set)\n",
    "    tr_targets = X_tr_value.astype(int).reshape(-1)\n",
    "    tr_one_hot_targets = np.eye(nb_class)[tr_targets]\n",
    "    \n",
    "    va_targets = X_va_value.astype(int).reshape(-1)\n",
    "    va_one_hot_targets = np.eye(nb_class)[va_targets]\n",
    "    \n",
    "    te_targets = X_te_value.astype(int).reshape(-1)\n",
    "    te_one_hot_targets = np.eye(nb_class)[te_targets]\n",
    "    \n",
    "    #print(tr_one_hot_targets)\n",
    "    #print(va_one_hot_targets)\n",
    "    #print(te_one_hot_targets)\n",
    "    \n",
    "    X_tr = np.concatenate((X_tr,tr_one_hot_targets),axis = 1)\n",
    "    X_va = np.concatenate((X_va,va_one_hot_targets),axis = 1)\n",
    "    X_te = np.concatenate((X_te,te_one_hot_targets),axis = 1)\n",
    "\n",
    "# Delete previous categorical features\n",
    "X_tr = np.delete(X_tr, categorical_feature, 1)\n",
    "X_va = np.delete(X_va, categorical_feature, 1)\n",
    "X_te = np.delete(X_te, categorical_feature, 1)\n",
    "# End your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118, 28), (89, 28), (90, 28))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_va.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Logistic regression model and regularizer\n",
    "Build logistic regression model with l2 regularization utilizing sklearn. <br>\n",
    "Find the optimal coefficient based on <b>cross entropy loss</b> on thet validation set. <br>\n",
    "Try following regularization parameter settings.\n",
    "* Regularization parameters = 0.01, 0.05, 0.1, 0.5, 1, 10, 100 <br>\n",
    "* Note that regluarization parameter for LogisticRegression in sklearn is inverse of true parameter. <br>\n",
    "  (coef = 0.001 for LogisticRegression   =>  $\\lambda$ = 1000 in our course note)\n",
    "* Your model should be <b>LogisticRegression(C=coef, solver='lbfgs', max_iter=500). </b>\n",
    "  <br>  <b>Do not change the model setting except C. </b> \n",
    "  <br> (coef = each regularization parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use below function\n",
    "# logreg = LogisticRegression(C=coef, solver='lbfgs', max_iter=500)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "coefs = [0.01, 0.05, 0.1, 0.5, 1, 10, 100]\n",
    "\n",
    "opt_coef = 1\n",
    "\n",
    "\n",
    "# To plot losses on training and validation sets with varied parameter settings, \n",
    "# save them on lists.\n",
    "loss_tr, loss_va = [],[]\n",
    "\n",
    "# Your code here\n",
    "\n",
    "for coef in coefs:\n",
    "    logreg = LogisticRegression(C=coef, solver='lbfgs', max_iter=500)\n",
    "    logreg.fit(X_tr, Y_tr)\n",
    "    loss_tr.append(log_loss(Y_tr,logreg.predict_proba(X_tr)))\n",
    "    loss_va.append(log_loss(Y_va,logreg.predict_proba(X_va)))\n",
    "\n",
    "# End your code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Plot error\n",
    "Plot the train and validation loss against given regularization parameter <b>(not inverse)</b>.<br>\n",
    "<b> Analyze the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do not fix the code!!\n",
    "\n",
    "plt.plot(coefs, loss_tr, coefs, loss_va, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze \n",
    "Write explanation of graph below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "patameter C가 작을수록 regularization이 많이 됩니다. 위의 그래프에서 파란 선은 training error이고, 빨간 선은 validation error를 의미합니다. parameter C가 작을수록 regularization이 많이 되므로, X 값이 증가할수록, regularization은 적게 됨을 알 수 있습니다.\n",
    "\n",
    "training error는 regularization이 적게 될 수록 줄어들고, validation error의 경우,regularization이 적게 될수록 어느 지점까지는 줄어들지만, 다시 늘어남을 확인할 수 있습니다. \n",
    "\n",
    "regularization이 많이 된 지점에서는 training error와 validation error가 모두 높고, 이는 high bias되었다고 판단할 수 있습니다. regularization이 적게 된 지점에서는 training error는 낮지만, validation error는 다시 증가하는 양상을 보이므로, high variance되었다고 판단할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Model selection and evaluation\n",
    "\n",
    "Drop the performance on test set with the regularization coefficient of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal : 0.5, Loss : 0.370, Accuracy : 84.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Your code here\n",
    "\n",
    "for (i,coef) in enumerate(coefs):\n",
    "    logreg = LogisticRegression(C=coef, solver='lbfgs', max_iter=500)\n",
    "    logreg.fit(X_tr, Y_tr)\n",
    "    loss_tr.append(log_loss(Y_tr,logreg.predict_proba(X_tr)))\n",
    "    loss_va.append(log_loss(Y_va,logreg.predict_proba(X_va)))\n",
    "    if loss_va[i] == np.min(loss_va):\n",
    "        opt_coef = coef\n",
    "\n",
    "test_logreg = LogisticRegression(C=opt_coef, solver='lbfgs', max_iter=500)\n",
    "test_logreg.fit(X_tr, Y_tr)\n",
    "test_loss = log_loss(Y_te,test_logreg.predict_proba(X_te))\n",
    "test_acc = test_logreg.score(X_te,Y_te)\n",
    "coef = opt_coef\n",
    "# End your code\n",
    "\n",
    "\n",
    "#print regularization paramter of final model and drop test loss and accuracy\n",
    "print (\"Optimal : {}, Loss : {:2.3f}, Accuracy : {:3.2f}\".format(coef, test_loss, test_acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
