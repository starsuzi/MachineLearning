{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2\n",
    "\n",
    "#### Machine Learning in Korea University\n",
    "#### COSE362, Fall 2018\n",
    "#### Due : 11/26 (TUE) 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this assignment, you will learn various classification methods with given datasets.\n",
    "* Implementation detail: Anaconda 5.3 with python 3.7\n",
    "* Use given dataset. Please do not change train / valid / test split.\n",
    "* Use numpy, scikit-learn, and matplotlib library\n",
    "* You don't have to use all imported packages below. (some are optional). <br>\n",
    "Also, you can import additional packages in \"(Option) Other Classifiers\" part. \n",
    "* <b>*DO NOT MODIFY OTHER PARTS OF CODES EXCEPT \"Your Code Here\"*</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Additional packages\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your own packages if you need(only in scikit-learn, numpy, pandas).\n",
    "# Your Code Here\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm,grid_search\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#warning\n",
    "## Solve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "#End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "\n",
    "> 1. Load \"train.csv\". It includes all samples' features and labels.\n",
    "> 2. Training four types of classifiers(logistic regression, decision tree, random forest, support vector machine) and <b>validate</b> it in your own way. <b>(You can't get full credit if you don't conduct validation)</b>\n",
    "> 3. Optionally, if you would train your own classifier(e.g. ensembling or gradient boosting), you can evaluate your own model on the development data. <br>\n",
    "> 4. <b>You should submit your predicted results on test data with the selected classifier in your own manner.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task & dataset description\n",
    "1. 6 Features (1~6)<br>\n",
    "Feature 2, 4, 6 : Real-valued<br>\n",
    "Feature 1, 3, 5 : Categorical <br>\n",
    "\n",
    "2. Samples <br>\n",
    ">In development set : 2,000 samples <br>\n",
    ">In test set : 1,500 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load development dataset\n",
    "Load your development dataset. You should read <b>\"train.csv\"</b>. This is a classification task, and you need to preprocess your data for training your model. <br>\n",
    "> You need to use <b>1-of-K coding scheme</b>, to convert categorical features to one-hot vector. <br>\n",
    "> For example, if there are 3 categorical values, you can convert these features as [1,0,0], [0,1,0], [0,0,1] by 1-of-K coding scheme. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training your model, you need to convert categorical features to one-hot encoding vectors.\n",
    "# Your Code Here\n",
    "#load data\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "\n",
    "#one-hot\n",
    "df_train_onehot = pd.get_dummies(df_train.drop(columns=['feature2','feature4','feature6','target']))\n",
    "df_train = pd.concat([df_train,df_train_onehot], axis=1)\n",
    "df_train.drop(['feature1','feature3','feature5'], axis = 1, inplace = True)\n",
    "\n",
    "#feature && label\n",
    "data = df_train.drop(['target'],axis = 1,inplace = False)\n",
    "target = df_train.target\n",
    "\n",
    "#functions for cv\n",
    "def calc_train_error(X_train, y_train, model):\n",
    "    predictions = model.predict(X_train)\n",
    "    f1_train = f1_score(y_train, predictions, average='macro')\n",
    "    return f1_train\n",
    "\n",
    "def calc_test_error(X_val, y_val, model):\n",
    "    predictions = model.predict(X_val)\n",
    "    f1_val = f1_score(y_val, predictions, average='macro')\n",
    "    return f1_val\n",
    "    \n",
    "def calc_metrics(X_train, y_train, X_val, y_val, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    train_error = calc_train_error(X_train, y_train, model)\n",
    "    val_error= calc_test_error(X_val, y_val, model)\n",
    "    return train_error, val_error\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature2', 'feature4', 'feature6', 'target', 'feature1_a',\n",
       "       'feature1_b', 'feature1_c', 'feature1_d', 'feature3_a', 'feature3_b',\n",
       "       'feature3_c', 'feature3_d', 'feature3_e', 'feature3_f', 'feature3_g',\n",
       "       'feature3_h', 'feature5_a', 'feature5_b', 'feature5_c', 'feature5_d',\n",
       "       'feature5_e', 'feature5_f', 'feature5_g', 'feature5_h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature6</th>\n",
       "      <th>target</th>\n",
       "      <th>feature1_a</th>\n",
       "      <th>feature1_b</th>\n",
       "      <th>feature1_c</th>\n",
       "      <th>feature1_d</th>\n",
       "      <th>feature3_a</th>\n",
       "      <th>feature3_b</th>\n",
       "      <th>...</th>\n",
       "      <th>feature3_g</th>\n",
       "      <th>feature3_h</th>\n",
       "      <th>feature5_a</th>\n",
       "      <th>feature5_b</th>\n",
       "      <th>feature5_c</th>\n",
       "      <th>feature5_d</th>\n",
       "      <th>feature5_e</th>\n",
       "      <th>feature5_f</th>\n",
       "      <th>feature5_g</th>\n",
       "      <th>feature5_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature2  feature4  feature6  target  feature1_a  feature1_b  feature1_c  \\\n",
       "0         1         5         2       3           1           0           0   \n",
       "1         2         8         2      15           0           1           0   \n",
       "2         1         3         7       6           0           1           0   \n",
       "3         1         5         7      13           0           0           1   \n",
       "4         3         2         4      15           0           0           0   \n",
       "\n",
       "   feature1_d  feature3_a  feature3_b     ...      feature3_g  feature3_h  \\\n",
       "0           0           0           0     ...               0           0   \n",
       "1           0           1           0     ...               0           0   \n",
       "2           0           0           0     ...               0           0   \n",
       "3           0           1           0     ...               0           0   \n",
       "4           1           0           0     ...               0           1   \n",
       "\n",
       "   feature5_a  feature5_b  feature5_c  feature5_d  feature5_e  feature5_f  \\\n",
       "0           0           0           0           1           0           0   \n",
       "1           0           0           0           0           1           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   feature5_g  feature5_h  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           1           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature2', 'feature4', 'feature6', 'feature1_a', 'feature1_b',\n",
       "       'feature1_c', 'feature1_d', 'feature3_a', 'feature3_b', 'feature3_c',\n",
       "       'feature3_d', 'feature3_e', 'feature3_f', 'feature3_g', 'feature3_h',\n",
       "       'feature5_a', 'feature5_b', 'feature5_c', 'feature5_d', 'feature5_e',\n",
       "       'feature5_f', 'feature5_g', 'feature5_h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10876088 0.23943693 0.22982803 0.01282088 0.01304463 0.01651501\n",
      " 0.02017216 0.02697308 0.02812452 0.02528525 0.02490833 0.02887034\n",
      " 0.02848443 0.02743005 0.0268353  0.01995618 0.01402656 0.01520553\n",
      " 0.01516925 0.01576285 0.02021265 0.02424901 0.01792813]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# fit an Extra Trees model to the data\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(data,target)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(data, target)\n",
    "features = fit.transform(data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261.042  32.881 463.79  310.517  82.854  69.295 152.994  47.463  30.991\n",
      "  48.901  15.011  27.886  25.868  51.347  12.539 173.214  52.463  50.316\n",
      "  72.091  71.496  22.83   27.619 107.541]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Train and validate your <b>logistic regression classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(f1_train):  0.3571 | mean(f1_validation): 0.242\n",
      "mean(f1_train):  0.3663 | mean(f1_validation): 0.2446\n",
      "mean(f1_train):  0.3698 | mean(f1_validation): 0.2452\n",
      "mean(f1_train):  0.3656 | mean(f1_validation): 0.2471\n",
      "mean(f1_train):  0.3664 | mean(f1_validation): 0.2473\n",
      "======================\n",
      "validation f1_score\n",
      "0.24523288539881988\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# Training your logistic regression classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "#hyperparameter\n",
    "clf = LogisticRegression()\n",
    "param_grid = {'C': [0.1, 0.3, 0.5, 0.7, 1, 1.3, 1.5], 'penalty': ['l1', 'l2']}\n",
    "gridsearch = GridSearchCV(clf, \n",
    "                          param_grid,\n",
    "                          scoring = \"f1_macro\")\n",
    "gridsearch.fit(data, target)\n",
    "\n",
    "#Create Pipeline\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "#Create K-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1_trains = []\n",
    "f1_vals = []\n",
    "f1_val_result = []\n",
    "\n",
    "for train_index, val_index in kf.split(data, target):\n",
    "        \n",
    "    #split data\n",
    "    X_train, X_val = data.iloc[train_index], data.iloc[val_index]\n",
    "    y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "        \n",
    "    #instantaite model\n",
    "    #Create a pipleline that standardized, then runs logistic regression\n",
    "    pipeline = make_pipeline(standardizer,\n",
    "                             LogisticRegression(random_state = 42,\n",
    "                                                C = gridsearch.best_params_['C'], \n",
    "                                                penalty=gridsearch.best_params_['penalty']))\n",
    "        \n",
    "    #calculate errors\n",
    "    f1_train, f1_val = calc_metrics(X_train, y_train, X_val, y_val, pipeline)\n",
    "        \n",
    "    #append tp appropriate list\n",
    "    f1_trains.append(f1_train)\n",
    "    f1_vals.append(f1_val)\n",
    "    \n",
    "    f1_val_result.append(np.mean(f1_vals))\n",
    "    \n",
    "#generate report\n",
    "    print('mean(f1_train): {:7} | mean(f1_validation): {}'.\n",
    "            format(\n",
    "            round(np.mean(f1_trains),4),\n",
    "            round(np.mean(f1_vals),4)\n",
    "            ))\n",
    "    \n",
    "#print(np.mean(f1_vals))\n",
    "print(\"======================\")\n",
    "print(\"validation f1_score\")\n",
    "print(np.mean(f1_val_result))\n",
    "print(\"======================\")\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Train and validate your <b>decision tree classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(f1_train):     1.0 | mean(f1_validation): 0.3403 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.3566 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.3644 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.3776 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.3751 \n",
      "======================\n",
      "validation f1_score\n",
      "0.3628007526976968\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# Training your decision tree classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "#Create Pipeline\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "#Create K-fold cross-validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1_trains = []\n",
    "f1_vals = []\n",
    "f1_val_result = []\n",
    "\n",
    "for train_index, val_index in kf.split(data, target):       \n",
    "    #split data\n",
    "    X_train, X_val = data.iloc[train_index], data.iloc[val_index]\n",
    "    y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "        \n",
    "    #instantaite model\n",
    "    #Create a pipleline that standardized, then runs logistic regression\n",
    "    pipeline = make_pipeline(standardizer,\n",
    "                            DecisionTreeClassifier(random_state = 42))\n",
    "        \n",
    "    #calculate errors\n",
    "    f1_train, f1_val = calc_metrics(X_train, y_train, X_val, y_val, pipeline)\n",
    "        \n",
    "    #append tp appropriate list\n",
    "    f1_trains.append(f1_train)\n",
    "    f1_vals.append(f1_val)\n",
    "    \n",
    "    f1_val_result.append(np.mean(f1_vals))\n",
    "    \n",
    "    #generate report\n",
    "    print('mean(f1_train): {:7} | mean(f1_validation): {} '.\n",
    "        format(\n",
    "                round(np.mean(f1_trains),4),\n",
    "                round(np.mean(f1_vals),4)\n",
    "                ))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(\"validation f1_score\")\n",
    "print(np.mean(f1_val_result))\n",
    "print(\"======================\")\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Train and validate your <b>random forest classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(f1_train):     1.0 | mean(f1_validation): 0.5132 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.4745 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.4431 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.4477 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.4435 \n",
      "======================\n",
      "validation f1_score\n",
      "0.464401899460837\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# Training your random forest classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "#Create Pipeline\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "#Create K-fold cross-validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1_trains = []\n",
    "f1_vals = []\n",
    "f1_val_result = []\n",
    "\n",
    "for train_index, val_index in kf.split(data, target):       \n",
    "    #split data\n",
    "    X_train, X_val = data.iloc[train_index], data.iloc[val_index]\n",
    "    y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "        \n",
    "    #instantaite model\n",
    "    #Create a pipleline that standardized, then runs logistic regression\n",
    "    pipeline = make_pipeline(standardizer,\n",
    "                            RandomForestClassifier(n_estimators=400,\n",
    "                                                   random_state=42))\n",
    "        \n",
    "    #calculate errors\n",
    "    f1_train, f1_val = calc_metrics(X_train, y_train, X_val, y_val, pipeline)\n",
    "        \n",
    "    #append tp appropriate list\n",
    "    f1_trains.append(f1_train)\n",
    "    f1_vals.append(f1_val)\n",
    "    \n",
    "    f1_val_result.append(np.mean(f1_vals))\n",
    "    \n",
    "    #generate report\n",
    "    print('mean(f1_train): {:7} | mean(f1_validation): {} '.\n",
    "        format(\n",
    "                round(np.mean(f1_trains),4),\n",
    "                round(np.mean(f1_vals),4)\n",
    "                ))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(\"validation f1_score\")\n",
    "print(np.mean(f1_val_result))\n",
    "print(\"======================\")\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "Train and validate your <b>support vector machine classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_param_selection(data, target, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(f1_train):  0.9009 | mean(f1_validation): 0.3574 \n",
      "mean(f1_train):  0.8915 | mean(f1_validation): 0.3595 \n",
      "mean(f1_train):  0.9002 | mean(f1_validation): 0.3459 \n",
      "mean(f1_train):  0.8956 | mean(f1_validation): 0.339 \n",
      "mean(f1_train):  0.8913 | mean(f1_validation): 0.3446 \n",
      "======================\n",
      "validation f1_score\n",
      "0.3492606240610674\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# Training your support vector machine classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "#hyperparameter\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    \n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(\n",
    "                               svm.SVC(kernel='rbf',random_state = 42),\n",
    "                               param_grid, \n",
    "                               cv = nfolds,\n",
    "                               scoring='f1_macro')\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    \n",
    "    return grid_search.best_params_\n",
    "\n",
    "\n",
    "#Create Pipeline\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "#Create K-fold cross-validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1_trains = []\n",
    "f1_vals = []\n",
    "f1_val_result = []\n",
    "\n",
    "for train_index, val_index in kf.split(data, target):       \n",
    "    #split data\n",
    "    X_train, X_val = data.iloc[train_index], data.iloc[val_index]\n",
    "    y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "        \n",
    "    #instantaite model\n",
    "    #Create a pipleline that standardized, then runs logistic regression\n",
    "    pipeline = make_pipeline(standardizer,\n",
    "                            SVC(C = 10, \n",
    "                                gamma = 0.1, \n",
    "                                kernel='rbf',\n",
    "                                random_state = 42))\n",
    "        \n",
    "    #calculate errors\n",
    "    f1_train, f1_val = calc_metrics(X_train, y_train, X_val, y_val, pipeline)\n",
    "        \n",
    "    #append tp appropriate list\n",
    "    f1_trains.append(f1_train)\n",
    "    f1_vals.append(f1_val)\n",
    "    \n",
    "    f1_val_result.append(np.mean(f1_vals))\n",
    "    \n",
    "    #generate report\n",
    "    print('mean(f1_train): {:7} | mean(f1_validation): {} '.\n",
    "        format(\n",
    "                round(np.mean(f1_trains),4),\n",
    "                round(np.mean(f1_vals),4)\n",
    "                ))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(\"validation f1_score\")\n",
    "print(np.mean(f1_val_result))\n",
    "print(\"======================\")\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Option) Other Classifiers.\n",
    "Train and validate other classifiers by your own manner.\n",
    "> <b> If you need, you can import other models only in this cell, only in scikit-learn. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-30831c88d4cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters, cv = 5, n_jobs=-1)\n",
    "clf.fit(data, target)\n",
    "print(clf.score(trainX, trainY))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(f1_train):     1.0 | mean(f1_validation): 0.5228 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.5176 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.4874 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.4689 \n",
      "mean(f1_train):     1.0 | mean(f1_validation): 0.4734 \n",
      "======================\n",
      "validation f1_score\n",
      "0.4940271842008638\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# If you need additional packages, import your own packages below.\n",
    "# Your Code Here\n",
    "\n",
    "\n",
    "#Create Pipeline\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "#Create K-fold cross-validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1_trains = []\n",
    "f1_vals = []\n",
    "f1_val_result = []\n",
    "\n",
    "for train_index, val_index in kf.split(data, target):       \n",
    "    #split data\n",
    "    X_train, X_val = data.iloc[train_index], data.iloc[val_index]\n",
    "    y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "        \n",
    "    #instantaite model\n",
    "    #Create a pipleline that standardized, then runs logistic regression\n",
    "    pipeline = make_pipeline(standardizer,\n",
    "                             GradientBoostingClassifier(\n",
    "                                                       random_state = 42,\n",
    "                                                       min_samples_split = 10,\n",
    "                                                       n_estimators=400,\n",
    "                                                       max_depth = 5,\n",
    "                                                       subsample = 0.8,\n",
    "                                                       learning_rate = 0.1,\n",
    "                                                       max_features = 'sqrt'\n",
    "                                                      )\n",
    "                            )\n",
    "        \n",
    "    #calculate errors\n",
    "    f1_train, f1_val = calc_metrics(X_train, y_train, X_val, y_val, pipeline)\n",
    "        \n",
    "    #append tp appropriate list\n",
    "    f1_trains.append(f1_train)\n",
    "    f1_vals.append(f1_val)\n",
    "    \n",
    "    f1_val_result.append(np.mean(f1_vals))\n",
    "    \n",
    "    #generate report\n",
    "    print('mean(f1_train): {:7} | mean(f1_validation): {} '.\n",
    "        format(\n",
    "                round(np.mean(f1_trains),4),\n",
    "                round(np.mean(f1_vals),4)\n",
    "                ))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(\"validation f1_score\")\n",
    "print(np.mean(f1_val_result))\n",
    "print(\"======================\")\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좀 걸리는데 성능은 확 올라갈거야 기다려봐요 :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(f1_train):  0.9947 | mean(f1_validation): 0.5837 \n",
      "mean(f1_train):  0.9943 | mean(f1_validation): 0.5369 \n",
      "mean(f1_train):   0.994 | mean(f1_validation): 0.4975 \n",
      "mean(f1_train):  0.9944 | mean(f1_validation): 0.4747 \n",
      "mean(f1_train):  0.9946 | mean(f1_validation): 0.4769 \n",
      "======================\n",
      "validation f1_score\n",
      "0.5139382956863877\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# If you need additional packages, import your own packages below.\n",
    "# Your Code Here\n",
    "\n",
    "#Create Pipeline\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "#Create K-fold cross-validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1_trains = []\n",
    "f1_vals = []\n",
    "f1_val_result = []\n",
    "\n",
    "for train_index, val_index in kf.split(data, target):       \n",
    "    #split data\n",
    "    X_train, X_val = data.iloc[train_index], data.iloc[val_index]\n",
    "    y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "        \n",
    "    #instantaite model\n",
    "    #Create a pipleline that standardized, then run\n",
    "    pipeline = make_pipeline(standardizer,\n",
    "                             GradientBoostingClassifier(\n",
    "                                                       random_state = 42,\n",
    "                                                       n_estimators = 400,  \n",
    "                                                       subsample = 0.8\n",
    "                                                      )\n",
    "                            )\n",
    "        \n",
    "    #calculate errors\n",
    "    f1_train, f1_val = calc_metrics(X_train, y_train, X_val, y_val, pipeline)\n",
    "        \n",
    "    #append tp appropriate list\n",
    "    f1_trains.append(f1_train)\n",
    "    f1_vals.append(f1_val)\n",
    "    \n",
    "    f1_val_result.append(np.mean(f1_vals))\n",
    "    \n",
    "    #generate report\n",
    "    print('mean(f1_train): {:7} | mean(f1_validation): {} '.\n",
    "        format(\n",
    "                round(np.mean(f1_trains),4),\n",
    "                round(np.mean(f1_vals),4)\n",
    "                ))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(\"validation f1_score\")\n",
    "print(np.mean(f1_val_result))\n",
    "print(\"======================\")\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(standardizer,\n",
    "                         GradientBoostingClassifier(\n",
    "                                                    random_state = 42,\n",
    "                                                    n_estimators = 400,  \n",
    "                                                    subsample = 0.8\n",
    "                                                    )\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your prediction on the test data.\n",
    "\n",
    "* Select your model and explain it briefly.\n",
    "* You should read <b>\"test.csv\"</b>.\n",
    "* Prerdict your model in array form.\n",
    "* Prediction example <br>\n",
    "[2, 6, 14, 8, $\\cdots$]\n",
    "* We will rank your result by <b>F1 metric(with 'macro' option)</b>.\n",
    "* <b> If you don't submit prediction file or submit it in wrong format, you can't get the point for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain your final model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset.\n",
    "# Your Code Here\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target class\n",
    "# Make variable \"my_answer\", type of array, and fill this array with your class predictions.\n",
    "# Modify file name into your student number and your name.\n",
    "# Your Code Here\n",
    "my_answer = []\n",
    "\n",
    "#one-hot\n",
    "df_test_onehot = pd.get_dummies(df_test.drop(columns=['feature2','feature4','featrure6']))\n",
    "df_test = pd.concat([df_test,df_test_onehot], axis=1)\n",
    "df_test.drop(['feature1','feature3','feature5'], axis = 1, inplace = True)\n",
    "\n",
    "logreg_test = logreg.predict(df_test)\n",
    "\n",
    "file_name = \"HW2_2016320120_정소영.csv\"\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, ..., 1, 6, 2], dtype=int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is for saving predicted answers. DO NOT MODIFY.\n",
    "pd.Series(my_answer).to_csv(\"./data/\" + file_name, header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
